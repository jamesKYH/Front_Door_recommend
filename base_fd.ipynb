{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2b3FwVZtUed",
        "outputId": "3389a9c0-abe7-4f3c-be14-862901cd03be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment Ready.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 멀티스레드 설정\n",
        "torch.set_num_threads(8)\n",
        "\n",
        "print(\"Environment Ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2\n",
        "\n",
        "!pip install scikit-surprise > /dev/null\n",
        "\n",
        "from surprise import Dataset, Reader\n",
        "\n",
        "class MovieLens:\n",
        "    def __init__(self, ratings_path, movies_path):\n",
        "        self.ratingsPath = ratings_path\n",
        "        self.moviesPath = movies_path\n",
        "        self.movieID_to_name = {}\n",
        "        self.name_to_movieID = {}\n",
        "\n",
        "    def loadMovieLensLatestSmall(self):\n",
        "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1, rating_scale=(1,5))\n",
        "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
        "\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                movieName = row[1]\n",
        "                self.movieID_to_name[movieID] = movieName\n",
        "                self.name_to_movieID[movieName] = movieID\n",
        "\n",
        "        return ratingsDataset\n",
        "\n",
        "    def getPopularityRanks(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = {}\n",
        "        with open(self.ratingsPath, newline='', encoding='utf-8') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                movieID = int(row[1])\n",
        "                ratings[movieID] += 1\n",
        "        rank = 1\n",
        "        for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[movieID] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "\n",
        "    def getGenres(self):\n",
        "        genres = defaultdict(list)\n",
        "        genreIDs = {}\n",
        "        maxGenreID = 0\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                genreList = row[2].split('|')\n",
        "                genreIDList = []\n",
        "                for genre in genreList:\n",
        "                    if genre in genreIDs:\n",
        "                        genreID = genreIDs[genre]\n",
        "                    else:\n",
        "                        genreID = maxGenreID\n",
        "                        genreIDs[genre] = genreID\n",
        "                        maxGenreID += 1\n",
        "                    genreIDList.append(genreID)\n",
        "                genres[movieID] = genreIDList\n",
        "\n",
        "        for movieID, genreIDList in genres.items():\n",
        "            bitfield = [0]*maxGenreID\n",
        "            for g in genreIDList:\n",
        "                bitfield[g] = 1\n",
        "            genres[movieID] = bitfield\n",
        "        return genres\n",
        "\n",
        "def surprise_dataset_to_list(surprise_dataset):\n",
        "    raw_data = surprise_dataset.raw_ratings\n",
        "    data_list = []\n",
        "    for (user, item, rating, _) in raw_data:\n",
        "        data_list.append((int(user), int(item), float(rating)))\n",
        "    return data_list\n",
        "\n",
        "def train_test_split(data_list, test_ratio=0.2, seed=42):\n",
        "    random.Random(seed).shuffle(data_list)\n",
        "    cutoff = int(len(data_list)*(1 - test_ratio))\n",
        "    train_data = data_list[:cutoff]\n",
        "    test_data = data_list[cutoff:]\n",
        "    return train_data, test_data\n",
        "\n",
        "# 파일 경로 예시\n",
        "ratings_path = \"/content/ratings.csv\"\n",
        "movies_path = \"/content/movies.csv\"\n",
        "\n",
        "ml = MovieLens(ratings_path, movies_path)\n",
        "surprise_dataset = ml.loadMovieLensLatestSmall()\n",
        "data_list = surprise_dataset_to_list(surprise_dataset)\n",
        "\n",
        "train_data, test_data = train_test_split(data_list, test_ratio=0.2, seed=42)\n",
        "print(\"Data Loaded.\")\n",
        "print(\"Train size:\", len(train_data), \"Test size:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orbNweaqtoY1",
        "outputId": "ab7b9b89-2070-4bdc-f2d5-3f61996b20e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded.\n",
            "Train size: 80003 Test size: 20001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    return math.sqrt(np.mean((np.array(predictions) - np.array(targets))**2))\n",
        "\n",
        "def mae(predictions, targets):\n",
        "    return np.mean(np.abs(np.array(predictions) - np.array(targets)))\n",
        "\n",
        "def prune_items_by_popularity(all_items, popularity_ranks, top_k=2000):\n",
        "    items_with_rank = [(itm, popularity_ranks.get(itm,9999999)) for itm in all_items]\n",
        "    items_with_rank.sort(key=lambda x: x[1])  # rank 오름차순(1이 가장 인기)\n",
        "    pruned = [x[0] for x in items_with_rank[:top_k]]\n",
        "    return set(pruned)\n",
        "\n",
        "def get_topN_for_all_users(model, all_users, candidate_items, user_items_dict, N=10):\n",
        "    user_topN = {}\n",
        "    for u in all_users:\n",
        "        rated_items = user_items_dict[u]\n",
        "        cands = [i for i in candidate_items if i not in rated_items]\n",
        "        scores = []\n",
        "        for i in cands:\n",
        "            pred = model.predict(u,i)\n",
        "            scores.append((i,pred))\n",
        "        scores.sort(key=lambda x:x[1], reverse=True)\n",
        "        user_topN[u] = [x[0] for x in scores[:N]]\n",
        "    return user_topN\n",
        "\n",
        "def coverage_with_topN(user_topN, all_items):\n",
        "    recommended = set()\n",
        "    for u, top_items in user_topN.items():\n",
        "        for i in top_items:\n",
        "            recommended.add(i)\n",
        "    return len(recommended)/len(all_items) if len(all_items)>0 else 0.0\n",
        "\n",
        "def diversity_with_topN(user_topN, movie_genres):\n",
        "    distances = []\n",
        "    for u, top_items in user_topN.items():\n",
        "        if len(top_items)<2:\n",
        "            continue\n",
        "        pair_sum=0.0\n",
        "        pair_count=0\n",
        "        for i1 in range(len(top_items)):\n",
        "            for i2 in range(i1+1,len(top_items)):\n",
        "                it1 = top_items[i1]\n",
        "                it2 = top_items[i2]\n",
        "                g1 = movie_genres.get(it1, [])\n",
        "                g2 = movie_genres.get(it2, [])\n",
        "                if len(g1)==len(g2):\n",
        "                    inter=0\n",
        "                    union=0\n",
        "                    for x,y in zip(g1,g2):\n",
        "                        if x==1 and y==1: inter+=1\n",
        "                        if x==1 or y==1: union+=1\n",
        "                    if union>0:\n",
        "                        jacc_dist = 1 - (inter/union)\n",
        "                        pair_sum+= jacc_dist\n",
        "                        pair_count+=1\n",
        "        if pair_count>0:\n",
        "            distances.append(pair_sum/pair_count)\n",
        "    if len(distances)==0:\n",
        "        return 0.0\n",
        "    return float(np.mean(distances))\n",
        "\n",
        "def novelty_with_topN(user_topN, popularity_ranks):\n",
        "    ranks=[]\n",
        "    for u, top_items in user_topN.items():\n",
        "        for i in top_items:\n",
        "            ranks.append(popularity_ranks.get(i,9999999))\n",
        "    if len(ranks)==0:\n",
        "        return 0.0\n",
        "    return float(np.mean(ranks))\n",
        "\n",
        "def evaluate_topN_metrics(user_topN, test_data, rating_threshold=4.0, N=10):\n",
        "    hits_hr = 0\n",
        "    total_hr = 0\n",
        "    user_hits_count=defaultdict(int)\n",
        "    user_above_thr=defaultdict(int)\n",
        "    sum_ranks=0\n",
        "    count_ranks=0\n",
        "\n",
        "    user_topN_rank={}\n",
        "    for u, items in user_topN.items():\n",
        "        rank_map={}\n",
        "        for idx, it in enumerate(items):\n",
        "            rank_map[it] = idx+1\n",
        "        user_topN_rank[u]=rank_map\n",
        "\n",
        "    for (u,i,r) in test_data:\n",
        "        if r>=rating_threshold:\n",
        "            total_hr+=1\n",
        "            if u in user_topN and i in user_topN[u]:\n",
        "                hits_hr+=1\n",
        "\n",
        "            user_above_thr[u]+=1\n",
        "            if u in user_topN_rank and i in user_topN_rank[u]:\n",
        "                rank_i = user_topN_rank[u][i]\n",
        "                user_hits_count[u]+=1\n",
        "            else:\n",
        "                rank_i = N+1\n",
        "            sum_ranks += rank_i\n",
        "            count_ranks+=1\n",
        "\n",
        "    hr_val = hits_hr/total_hr if total_hr>0 else 0.0\n",
        "    total_users_chr = sum(1 for x in user_above_thr if user_above_thr[x]>0)\n",
        "    total_hits_chr = sum(user_hits_count.values())\n",
        "    chr_val = total_hits_chr/total_users_chr if total_users_chr>0 else 0.0\n",
        "    ahar_val = sum_ranks/count_ranks if count_ranks>0 else 0.0\n",
        "\n",
        "    return hr_val, chr_val, ahar_val"
      ],
      "metadata": {
        "id": "dIlxU3VltsiF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4\n",
        "\n",
        "import pandas as pd\n",
        "from surprise import KNNBasic, SVD, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
        "\n",
        "from surprise import Dataset, Reader\n",
        "\n",
        "class ClassicRecommender:\n",
        "    \"\"\"\n",
        "    A wrapper for various Surprise-based classic CF methods:\n",
        "     - userKNN: user-based KNN\n",
        "     - itemKNN: item-based KNN\n",
        "     - svd: SVD\n",
        "     etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, method='userKNN'):\n",
        "        self.method = method\n",
        "        self.algo = None\n",
        "\n",
        "        if method == 'userKNN':\n",
        "            sim_options = {'name': 'cosine', 'user_based': True}\n",
        "            self.algo = KNNBasic(sim_options=sim_options)\n",
        "        elif method == 'itemKNN':\n",
        "            sim_options = {'name': 'cosine', 'user_based': False}\n",
        "            self.algo = KNNBasic(sim_options=sim_options)\n",
        "        elif method == 'svd':\n",
        "            # 예시 파라미터\n",
        "            self.algo = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
        "        else:\n",
        "            # default\n",
        "            self.algo = SVD()\n",
        "\n",
        "    def train(self, train_data):\n",
        "        df = pd.DataFrame(train_data, columns=['user','item','rating'])\n",
        "        df['user'] = df['user'].astype(str)\n",
        "        df['item'] = df['item'].astype(str)\n",
        "\n",
        "        reader = Reader(rating_scale=(1,5))\n",
        "        dataset = Dataset.load_from_df(df, reader=reader)\n",
        "        trainset = dataset.build_full_trainset()\n",
        "        self.algo.fit(trainset)\n",
        "\n",
        "    def predict(self, user, item):\n",
        "        user_str = str(user)\n",
        "        item_str = str(item)\n",
        "        est = self.algo.predict(user_str, item_str).est\n",
        "        return est"
      ],
      "metadata": {
        "id": "keC0IVh7t23c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5\n",
        "\n",
        "# 1) 모델 생성\n",
        "userKNN_model = ClassicRecommender(method='userKNN')\n",
        "\n",
        "# 2) 학습\n",
        "userKNN_model.train(train_data)\n",
        "\n",
        "# 3) 평가\n",
        "all_users = set([d[0] for d in train_data] + [d[0] for d in test_data])\n",
        "all_items = set([d[1] for d in train_data] + [d[1] for d in test_data])\n",
        "\n",
        "user_items_dict = defaultdict(set)\n",
        "for (u,i,r) in train_data:\n",
        "    user_items_dict[u].add(i)\n",
        "\n",
        "ml_obj = MovieLens(ratings_path, movies_path)\n",
        "popularity_ranks = ml_obj.getPopularityRanks()\n",
        "movie_genres = ml_obj.getGenres()\n",
        "\n",
        "# -- RMSE, MAE\n",
        "preds, trues = [], []\n",
        "for (u,i,r) in test_data:\n",
        "    p = userKNN_model.predict(u,i)\n",
        "    preds.append(p)\n",
        "    trues.append(r)\n",
        "userKNN_rmse = rmse(preds,trues)\n",
        "userKNN_mae  = mae(preds,trues)\n",
        "\n",
        "# -- Top-N\n",
        "pruned_items = prune_items_by_popularity(all_items, popularity_ranks, top_k=2000)\n",
        "user_topN = get_topN_for_all_users(userKNN_model, all_users, pruned_items, user_items_dict, N=10)\n",
        "\n",
        "hr_val, chr_val, ahar_val = evaluate_topN_metrics(user_topN, test_data, rating_threshold=4.0, N=10)\n",
        "cov_val = coverage_with_topN(user_topN, all_items)\n",
        "div_val = diversity_with_topN(user_topN, movie_genres)\n",
        "nov_val = novelty_with_topN(user_topN, popularity_ranks)\n",
        "\n",
        "print(\"\\n=== [UserKNN] Evaluation ===\")\n",
        "print(f\"RMSE = {userKNN_rmse:.4f}\")\n",
        "print(f\"MAE  = {userKNN_mae:.4f}\")\n",
        "print(f\"HR   = {hr_val:.4f}\")\n",
        "print(f\"cHR  = {chr_val:.4f}\")\n",
        "print(f\"AHAR = {ahar_val:.4f}\")\n",
        "print(f\"Coverage  = {cov_val:.4f}\")\n",
        "print(f\"Diversity = {div_val:.4f}\")\n",
        "print(f\"Novelty   = {nov_val:.4f}\")\n",
        "\n",
        "# 4) 특정 사용자에게 추천된 영화 리스트 출력\n",
        "sample_user = 1  # 예: user=1\n",
        "if sample_user in user_topN:\n",
        "    recommended_ids = user_topN[sample_user]\n",
        "    recommended_titles = [ml_obj.movieID_to_name.get(mid, \"Unknown\") for mid in recommended_ids]\n",
        "    print(f\"\\n[User {sample_user}] Top-10 Recommended Movie IDs:\", recommended_ids)\n",
        "    print(f\"[User {sample_user}] Top-10 Recommended Movie Titles:\", recommended_titles)\n",
        "else:\n",
        "    print(f\"\\nUser {sample_user} not found in user_topN.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_5JGK2VuAxG",
        "outputId": "931c4d82-267b-4cfc-aef6-b6a3feefd911"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "\n",
            "=== [UserKNN] Evaluation ===\n",
            "RMSE = 0.9822\n",
            "MAE  = 0.7610\n",
            "HR   = 0.0231\n",
            "cHR  = 0.3698\n",
            "AHAR = 10.8643\n",
            "Coverage  = 0.0116\n",
            "Diversity = 0.7305\n",
            "Novelty   = 1027.5379\n",
            "\n",
            "[User 1] Top-10 Recommended Movie IDs: [105844, 7502, 1948, 1147, 1260, 3067, 31410, 905, 306, 1873]\n",
            "[User 1] Top-10 Recommended Movie Titles: ['Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6\n",
        "\n",
        "itemKNN_model = ClassicRecommender(method='itemKNN')\n",
        "itemKNN_model.train(train_data)\n",
        "\n",
        "preds, trues = [], []\n",
        "for (u,i,r) in test_data:\n",
        "    p = itemKNN_model.predict(u,i)\n",
        "    preds.append(p)\n",
        "    trues.append(r)\n",
        "itemKNN_rmse = rmse(preds,trues)\n",
        "itemKNN_mae  = mae(preds,trues)\n",
        "\n",
        "pruned_items = prune_items_by_popularity(all_items, popularity_ranks, top_k=2000)\n",
        "user_topN = get_topN_for_all_users(itemKNN_model, all_users, pruned_items, user_items_dict, N=10)\n",
        "\n",
        "hr_val, chr_val, ahar_val = evaluate_topN_metrics(user_topN, test_data, rating_threshold=4.0, N=10)\n",
        "cov_val = coverage_with_topN(user_topN, all_items)\n",
        "div_val = diversity_with_topN(user_topN, movie_genres)\n",
        "nov_val = novelty_with_topN(user_topN, popularity_ranks)\n",
        "\n",
        "print(\"\\n=== [ItemKNN] Evaluation ===\")\n",
        "print(f\"RMSE = {itemKNN_rmse:.4f}\")\n",
        "print(f\"MAE  = {itemKNN_mae:.4f}\")\n",
        "print(f\"HR   = {hr_val:.4f}\")\n",
        "print(f\"cHR  = {chr_val:.4f}\")\n",
        "print(f\"AHAR = {ahar_val:.4f}\")\n",
        "print(f\"Coverage  = {cov_val:.4f}\")\n",
        "print(f\"Diversity = {div_val:.4f}\")\n",
        "print(f\"Novelty   = {nov_val:.4f}\")\n",
        "\n",
        "# 특정 사용자 예시\n",
        "sample_user = 1\n",
        "if sample_user in user_topN:\n",
        "    recommended_ids = user_topN[sample_user]\n",
        "    recommended_titles = [ml_obj.movieID_to_name.get(mid, \"Unknown\") for mid in recommended_ids]\n",
        "    print(f\"\\n[User {sample_user}] Top-10 Recommended Movie IDs:\", recommended_ids)\n",
        "    print(f\"[User {sample_user}] Top-10 Recommended Movie Titles:\", recommended_titles)\n",
        "else:\n",
        "    print(f\"\\nUser {sample_user} not found in user_topN.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1obU72PuBhG",
        "outputId": "54395494-4013-4e85-b92f-a7777aebc405"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "\n",
            "=== [ItemKNN] Evaluation ===\n",
            "RMSE = 0.9856\n",
            "MAE  = 0.7673\n",
            "HR   = 0.0097\n",
            "cHR  = 0.1556\n",
            "AHAR = 10.9477\n",
            "Coverage  = 0.1660\n",
            "Diversity = 0.7955\n",
            "Novelty   = 1311.8376\n",
            "\n",
            "[User 1] Top-10 Recommended Movie IDs: [106696, 73, 60126, 105844, 66097, 546, 81932, 95167, 1873, 6867]\n",
            "[User 1] Top-10 Recommended Movie Titles: ['Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7\n",
        "\n",
        "svd_model = ClassicRecommender(method='svd')\n",
        "svd_model.train(train_data)\n",
        "\n",
        "preds, trues = [], []\n",
        "for (u,i,r) in test_data:\n",
        "    p = svd_model.predict(u,i)\n",
        "    preds.append(p)\n",
        "    trues.append(r)\n",
        "\n",
        "svd_rmse = rmse(preds,trues)\n",
        "svd_mae  = mae(preds,trues)\n",
        "\n",
        "pruned_items = prune_items_by_popularity(all_items, popularity_ranks, top_k=2000)\n",
        "user_topN = get_topN_for_all_users(svd_model, all_users, pruned_items, user_items_dict, N=10)\n",
        "\n",
        "hr_val, chr_val, ahar_val = evaluate_topN_metrics(user_topN, test_data, rating_threshold=4.0, N=10)\n",
        "cov_val = coverage_with_topN(user_topN, all_items)\n",
        "div_val = diversity_with_topN(user_topN, movie_genres)\n",
        "nov_val = novelty_with_topN(user_topN, popularity_ranks)\n",
        "\n",
        "print(\"\\n=== [SVD] Evaluation ===\")\n",
        "print(f\"RMSE = {svd_rmse:.4f}\")\n",
        "print(f\"MAE  = {svd_mae:.4f}\")\n",
        "print(f\"HR   = {hr_val:.4f}\")\n",
        "print(f\"cHR  = {chr_val:.4f}\")\n",
        "print(f\"AHAR = {ahar_val:.4f}\")\n",
        "print(f\"Coverage  = {cov_val:.4f}\")\n",
        "print(f\"Diversity = {div_val:.4f}\")\n",
        "print(f\"Novelty   = {nov_val:.4f}\")\n",
        "\n",
        "# 특정 사용자 예시\n",
        "sample_user = 1\n",
        "if sample_user in user_topN:\n",
        "    recommended_ids = user_topN[sample_user]\n",
        "    recommended_titles = [ml_obj.movieID_to_name.get(mid, \"Unknown\") for mid in recommended_ids]\n",
        "    print(f\"\\n[User {sample_user}] Top-10 Recommended Movie IDs:\", recommended_ids)\n",
        "    print(f\"[User {sample_user}] Top-10 Recommended Movie Titles:\", recommended_titles)\n",
        "else:\n",
        "    print(f\"\\nUser {sample_user} not found in user_topN.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccrbTw09uLvP",
        "outputId": "7ae45331-9d57-4617-cd5e-1969b4fafc93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== [SVD] Evaluation ===\n",
            "RMSE = 0.8878\n",
            "MAE  = 0.6850\n",
            "HR   = 0.0267\n",
            "cHR  = 0.4284\n",
            "AHAR = 10.8354\n",
            "Coverage  = 0.0246\n",
            "Diversity = 0.7556\n",
            "Novelty   = 424.4048\n",
            "\n",
            "[User 1] Top-10 Recommended Movie IDs: [318, 527, 1228, 858, 898, 1221, 1148, 1203, 912, 608]\n",
            "[User 1] Top-10 Recommended Movie Titles: ['Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-7eq5h8F57l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}