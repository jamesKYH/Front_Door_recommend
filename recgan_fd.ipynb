{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 멀티스레드(옵션)\n",
        "torch.set_num_threads(8)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFs_vgfxl8JN",
        "outputId": "910415d7-2497-4c37-e6a3-17cf064ec9eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2\n",
        "\n",
        "class MovieLens:\n",
        "    def __init__(self, ratings_path, movies_path=None):\n",
        "        self.ratings_path = ratings_path\n",
        "        self.movies_path  = movies_path or \"\"\n",
        "        self.movieID_to_name = {}\n",
        "        self.name_to_movieID = {}\n",
        "\n",
        "    def load_ratings_df(self):\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(self.ratings_path, header=0, encoding='utf-8')\n",
        "        return df\n",
        "\n",
        "    def load_movies(self):\n",
        "        \"\"\"\n",
        "        movies.csv -> movieID <-> name, etc. (옵션)\n",
        "        \"\"\"\n",
        "        pass  # 생략\n",
        "\n",
        "ratings_path = \"/content/ratings.csv\"\n",
        "ml = MovieLens(ratings_path)\n",
        "df = ml.load_ratings_df()\n",
        "\n",
        "# timestamp 열이 있다고 가정\n",
        "df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "cutoff_idx= int(len(df)*0.8)\n",
        "train_df  = df.iloc[:cutoff_idx]\n",
        "test_df   = df.iloc[cutoff_idx:]\n",
        "\n",
        "def build_user_sequences(df_):\n",
        "    from collections import defaultdict\n",
        "    seq_dict= defaultdict(list)\n",
        "    for row in df_.itertuples():\n",
        "        # (Index, userId, movieId, rating, timestamp)\n",
        "        user   = int(row.userId)\n",
        "        item   = int(row.movieId)\n",
        "        rating = float(row.rating)\n",
        "        seq_dict[user].append((item, rating))\n",
        "    return seq_dict\n",
        "\n",
        "user_seq_train = build_user_sequences(train_df)\n",
        "user_seq_test  = build_user_sequences(test_df)\n",
        "\n",
        "all_users = set(user_seq_train.keys()).union(user_seq_test.keys())\n",
        "all_items = set()\n",
        "for u, seq in user_seq_train.items():\n",
        "    for (i,r) in seq:\n",
        "        all_items.add(i)\n",
        "for u, seq in user_seq_test.items():\n",
        "    for (i,r) in seq:\n",
        "        all_items.add(i)\n",
        "\n",
        "num_users= max(all_users)+1\n",
        "num_items= max(all_items)+1\n",
        "\n",
        "print(\"Train user-seq:\", len(user_seq_train), \"Test user-seq:\", len(user_seq_test))\n",
        "print(\"num_users:\", num_users, \"num_items:\", num_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS1RwSMrl9NW",
        "outputId": "4ec5fc7c-b771-4cdf-abf4-258f521bc0de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train user-seq: 547 Test user-seq: 147\n",
            "num_users: 672 num_items: 163950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class UserSequenceDataset(Dataset):\n",
        "    def __init__(self, user_sequences, max_seq_len=10):\n",
        "        self.samples=[]\n",
        "        for u, seq in user_sequences.items():\n",
        "            if len(seq)<2:\n",
        "                continue\n",
        "            start=0\n",
        "            while start<len(seq):\n",
        "                end= min(start+max_seq_len, len(seq))\n",
        "                sub_seq= seq[start:end]\n",
        "                if len(sub_seq)>=2:\n",
        "                    items   = [x[0] for x in sub_seq]\n",
        "                    ratings = [x[1] for x in sub_seq]\n",
        "                    self.samples.append((u, items, ratings))\n",
        "                start=end\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    users, items_list, ratings_list, lengths= [], [], [], []\n",
        "    max_len=0\n",
        "    for (u,it,rt) in batch:\n",
        "        if len(it)>max_len:\n",
        "            max_len=len(it)\n",
        "\n",
        "    for (u,it,rt) in batch:\n",
        "        seq_len= len(it)\n",
        "        lengths.append(seq_len)\n",
        "        users.append(u)\n",
        "\n",
        "        pad_it= it + [0]*(max_len-seq_len)\n",
        "        pad_rt= rt + [0.0]*(max_len-seq_len)\n",
        "\n",
        "        items_list.append(pad_it)\n",
        "        ratings_list.append(pad_rt)\n",
        "\n",
        "    users_tensor   = torch.LongTensor(users)\n",
        "    items_tensor   = torch.LongTensor(items_list)\n",
        "    ratings_tensor = torch.FloatTensor(ratings_list)\n",
        "    lengths_tensor = torch.LongTensor(lengths)\n",
        "    return (users_tensor, items_tensor, ratings_tensor, lengths_tensor)"
      ],
      "metadata": {
        "id": "pAPQo-lhnEBc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4\n",
        "\n",
        "class GRUCellBasic(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.W_z = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.W_r = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.W_h = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        combined= torch.cat([x,h_prev],dim=1)\n",
        "        z= torch.sigmoid(self.W_z(combined))\n",
        "        r= torch.sigmoid(self.W_r(combined))\n",
        "        comb_r= torch.cat([x, r*h_prev],dim=1)\n",
        "        h_tilde= torch.tanh(self.W_h(comb_r))\n",
        "        h= (1-z)*h_prev + z*h_tilde\n",
        "        return h\n",
        "\n",
        "class GRUCellModified(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.W_z = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.W_r = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.W_h = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        combined= torch.cat([x,h_prev],dim=1)\n",
        "        z_pre= self.W_z(combined)\n",
        "        z= self.lrelu(z_pre)\n",
        "        r= torch.sigmoid(self.W_r(combined))\n",
        "        comb_r= torch.cat([x, r*h_prev],dim=1)\n",
        "        h_tilde= torch.tanh(self.W_h(comb_r))\n",
        "        h= (1-z)*h_prev + z*h_tilde\n",
        "        return h\n",
        "\n",
        "class RRecGAN_Generator(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embed_dim, hidden_size, gru_type='basic'):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embed_dim, padding_idx=0)\n",
        "        self.item_embedding = nn.Embedding(num_items, embed_dim, padding_idx=0)\n",
        "        self.rating_embedding= nn.Linear(1, embed_dim)\n",
        "\n",
        "        input_size= embed_dim*3\n",
        "        if gru_type=='basic':\n",
        "            self.gru_cell= GRUCellBasic(input_size, hidden_size)\n",
        "        else:\n",
        "            self.gru_cell= GRUCellModified(input_size, hidden_size)\n",
        "\n",
        "        self.output_layer= nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self, users, items, ratings, lengths):\n",
        "        device= items.device\n",
        "        batch_size, seq_len= items.size()\n",
        "        h= torch.zeros(batch_size, self.output_layer.in_features, device=device)\n",
        "\n",
        "        user_emb= self.user_embedding(users)\n",
        "        preds=[]\n",
        "        for t in range(seq_len):\n",
        "            it= items[:,t]\n",
        "            rt= ratings[:,t].unsqueeze(-1)\n",
        "            it_emb= self.item_embedding(it)\n",
        "            rt_emb= self.rating_embedding(rt)\n",
        "            x= torch.cat([user_emb, it_emb, rt_emb],dim=1)\n",
        "            h= self.gru_cell(x,h)\n",
        "            pred= self.output_layer(h)\n",
        "            preds.append(pred)\n",
        "        preds= torch.cat(preds, dim=1)\n",
        "        return preds\n",
        "\n",
        "class RRecGAN_Discriminator(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embed_dim, hidden_size, gru_type='basic'):\n",
        "        super().__init__()\n",
        "        self.user_embedding= nn.Embedding(num_users, embed_dim, padding_idx=0)\n",
        "        self.item_embedding= nn.Embedding(num_items, embed_dim, padding_idx=0)\n",
        "        self.rating_embedding= nn.Linear(1, embed_dim)\n",
        "\n",
        "        input_size= embed_dim*3\n",
        "        if gru_type=='basic':\n",
        "            self.gru_cell= GRUCellBasic(input_size, hidden_size)\n",
        "        else:\n",
        "            self.gru_cell= GRUCellModified(input_size, hidden_size)\n",
        "\n",
        "        self.output_layer= nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self, users, items, ratings, lengths):\n",
        "        device= items.device\n",
        "        batch_size, seq_len= items.size()\n",
        "        h= torch.zeros(batch_size, self.output_layer.in_features, device=device)\n",
        "\n",
        "        user_emb= self.user_embedding(users)\n",
        "        for t in range(seq_len):\n",
        "            it= items[:,t]\n",
        "            rt= ratings[:,t].unsqueeze(-1)\n",
        "            it_emb= self.item_embedding(it)\n",
        "            rt_emb= self.rating_embedding(rt)\n",
        "            x= torch.cat([user_emb, it_emb, rt_emb],dim=1)\n",
        "            h= self.gru_cell(x,h)\n",
        "        logit= self.output_layer(h)\n",
        "        out= torch.sigmoid(logit)\n",
        "        return out"
      ],
      "metadata": {
        "id": "pLVXietqnO6P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5\n",
        "\n",
        "def train_rrecgan(generator, discriminator, train_loader,\n",
        "                  num_epochs=15,\n",
        "                  g_lr=5e-4,\n",
        "                  d_lr=5e-4,\n",
        "                  lambda_mse=0.1,\n",
        "                  grad_clip=10.0,\n",
        "                  device='cuda',\n",
        "                  S_g=1, S_d=1):\n",
        "    import torch.nn.utils as nn_utils\n",
        "\n",
        "    gen_opt= optim.Adam(generator.parameters(), lr=g_lr)\n",
        "    dis_opt= optim.Adam(discriminator.parameters(), lr=d_lr)\n",
        "\n",
        "    bce_loss= nn.BCELoss()\n",
        "    mse_loss= nn.MSELoss()\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        epoch_g_loss=0.0\n",
        "        epoch_d_loss=0.0\n",
        "        batch_count=0\n",
        "\n",
        "        for (users, items, ratings, lengths) in train_loader:\n",
        "            users   = users.to(device)\n",
        "            items   = items.to(device)\n",
        "            ratings = ratings.to(device)\n",
        "            lengths = lengths.to(device)\n",
        "\n",
        "            batch_size= items.size(0)\n",
        "\n",
        "            # (1) Generator update\n",
        "            for _ in range(S_g):\n",
        "                gen_opt.zero_grad()\n",
        "                gen_ratings= generator(users, items, ratings, lengths)\n",
        "                d_out_gen= discriminator(users, items, gen_ratings, lengths)\n",
        "                real_labels= torch.ones(batch_size,1,device=device)\n",
        "\n",
        "                gan_loss= bce_loss(d_out_gen, real_labels)\n",
        "                rec_loss= mse_loss(gen_ratings, ratings)\n",
        "                g_loss= gan_loss + lambda_mse*rec_loss\n",
        "\n",
        "                g_loss.backward()\n",
        "                nn_utils.clip_grad_norm_(generator.parameters(), grad_clip)\n",
        "                gen_opt.step()\n",
        "\n",
        "            # (2) Discriminator update\n",
        "            for _ in range(S_d):\n",
        "                dis_opt.zero_grad()\n",
        "                # real\n",
        "                real_labels= torch.ones(batch_size,1,device=device)\n",
        "                d_out_real= discriminator(users, items, ratings, lengths)\n",
        "                d_loss_real= bce_loss(d_out_real, real_labels)\n",
        "\n",
        "                # fake\n",
        "                with torch.no_grad():\n",
        "                    fake_ratings= generator(users, items, ratings, lengths)\n",
        "                fake_labels= torch.zeros(batch_size,1,device=device)\n",
        "                d_out_fake= discriminator(users, items, fake_ratings, lengths)\n",
        "                d_loss_fake= bce_loss(d_out_fake, fake_labels)\n",
        "\n",
        "                d_loss= d_loss_real + d_loss_fake\n",
        "                d_loss.backward()\n",
        "                nn_utils.clip_grad_norm_(discriminator.parameters(), grad_clip)\n",
        "                dis_opt.step()\n",
        "\n",
        "            epoch_g_loss+= g_loss.item()\n",
        "            epoch_d_loss+= d_loss.item()\n",
        "            batch_count+=1\n",
        "\n",
        "        avg_g= epoch_g_loss/batch_count if batch_count>0 else 0.0\n",
        "        avg_d= epoch_d_loss/batch_count if batch_count>0 else 0.0\n",
        "        print(f\"[Epoch {epoch+1}/{num_epochs}] G_loss={avg_g:.4f}, D_loss={avg_d:.4f}\")\n",
        "\n",
        "    print(\"학습 완료!\")\n",
        "    return generator, discriminator"
      ],
      "metadata": {
        "id": "i8lWsPDAnT8Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "########################\n",
        "## 0) RMSE, MAE\n",
        "########################\n",
        "def rmse(predictions, targets):\n",
        "    return math.sqrt(np.mean((np.array(predictions)-np.array(targets))**2))\n",
        "\n",
        "def mae(predictions, targets):\n",
        "    return np.mean(np.abs(np.array(predictions)-np.array(targets)))\n",
        "\n",
        "########################\n",
        "## 1) 사용자별 Top-N\n",
        "########################\n",
        "def get_topN_for_all_users_recgan(model, all_users, all_items, user_items_dict,\n",
        "                                  popularity_ranks,\n",
        "                                  top_k_candidates=2000,\n",
        "                                  N=10):\n",
        "    \"\"\"\n",
        "     - 이미 평가한 아이템 제외\n",
        "     - 인기도 rank 기반 pruning (top_k_candidates)\n",
        "     - model (RecGAN Generator)로 (u,i) 평점 예측\n",
        "    \"\"\"\n",
        "    user_topN= {}\n",
        "    model.eval()\n",
        "\n",
        "    for u in all_users:\n",
        "        rated_items = user_items_dict[u]\n",
        "        # 후보군: all_items - rated_items\n",
        "        cands= [i for i in all_items if i not in rated_items]\n",
        "\n",
        "        # 인기 높은 아이템만 top_k_candidates개\n",
        "        if len(cands)> top_k_candidates:\n",
        "            cands= sorted(cands, key=lambda x: popularity_ranks.get(x,9999999))\n",
        "            cands= cands[:top_k_candidates]\n",
        "\n",
        "        scores=[]\n",
        "        for i in cands:\n",
        "            user_tensor   = torch.LongTensor([u]).to(device)\n",
        "            item_tensor   = torch.LongTensor([[i]]).to(device)\n",
        "            rating_tensor = torch.FloatTensor([[0.0]]).to(device)\n",
        "            length_tensor = torch.LongTensor([1]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pr_2d = model(user_tensor, item_tensor, rating_tensor, length_tensor)\n",
        "            pred_val= pr_2d.item()\n",
        "            scores.append((i,pred_val))\n",
        "\n",
        "        scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_items= [x[0] for x in scores[:N]]\n",
        "        user_topN[u] = top_items\n",
        "\n",
        "    return user_topN\n",
        "\n",
        "########################\n",
        "## 2) HR, cHR, AHAR\n",
        "########################\n",
        "def evaluate_topN_metrics(user_topN, test_data, rating_threshold=4.0, N=10):\n",
        "    \"\"\"\n",
        "    test_data: [(u,i,r), ...]\n",
        "    user_topN: {u: [item1, item2, ... itemN]}\n",
        "    - HR: hit ratio\n",
        "    - cHR\n",
        "    - AHAR\n",
        "    \"\"\"\n",
        "    hits_hr=0\n",
        "    total_hr=0\n",
        "    user_hits_count= defaultdict(int)\n",
        "    user_above_thr=  defaultdict(int)\n",
        "\n",
        "    # user_topN_rank\n",
        "    user_topN_rank= {}\n",
        "    for u, items in user_topN.items():\n",
        "        rank_map={}\n",
        "        for idx,it in enumerate(items):\n",
        "            rank_map[it]= idx+1\n",
        "        user_topN_rank[u]= rank_map\n",
        "\n",
        "    sum_ranks=0\n",
        "    count_ranks=0\n",
        "\n",
        "    for (u,i,r) in test_data:\n",
        "        if r>= rating_threshold:\n",
        "            total_hr+=1\n",
        "            if i in user_topN[u]:\n",
        "                hits_hr+=1\n",
        "\n",
        "            user_above_thr[u]+=1\n",
        "            rank_i= user_topN_rank[u].get(i, N+1)\n",
        "            sum_ranks+= rank_i\n",
        "            count_ranks+=1\n",
        "\n",
        "            if rank_i<=N:\n",
        "                user_hits_count[u]+=1\n",
        "\n",
        "    hr_val= hits_hr/ total_hr if total_hr>0 else 0.0\n",
        "    total_users_chr= sum(1 for k in user_above_thr if user_above_thr[k]>0)\n",
        "    total_hits_chr= sum(user_hits_count.values())\n",
        "    chr_val= total_hits_chr/total_users_chr if total_users_chr>0 else 0.0\n",
        "    ahar_val= sum_ranks/count_ranks if count_ranks>0 else 0.0\n",
        "\n",
        "    return hr_val, chr_val, ahar_val\n",
        "\n",
        "########################\n",
        "## 3) Coverage, Diversity, Novelty\n",
        "########################\n",
        "def coverage_with_topN(user_topN, all_items):\n",
        "    recommended= set()\n",
        "    for u, top_items in user_topN.items():\n",
        "        for it in top_items:\n",
        "            recommended.add(it)\n",
        "    return len(recommended)/ len(all_items) if len(all_items)>0 else 0.0\n",
        "\n",
        "def diversity_with_topN(user_topN, movie_genres):\n",
        "    distances=[]\n",
        "    for u, top_items in user_topN.items():\n",
        "        if len(top_items)<2:\n",
        "            continue\n",
        "        pair_sum=0.0\n",
        "        pair_count=0\n",
        "        for i1 in range(len(top_items)):\n",
        "            for i2 in range(i1+1, len(top_items)):\n",
        "                it1= top_items[i1]\n",
        "                it2= top_items[i2]\n",
        "                g1= movie_genres.get(it1,[])\n",
        "                g2= movie_genres.get(it2,[])\n",
        "                if len(g1)== len(g2):\n",
        "                    inter=0\n",
        "                    union=0\n",
        "                    for x,y in zip(g1,g2):\n",
        "                        if x==1 and y==1:\n",
        "                            inter+=1\n",
        "                        if x==1 or y==1:\n",
        "                            union+=1\n",
        "                    if union>0:\n",
        "                        jacc_dist= 1-(inter/union)\n",
        "                        pair_sum+= jacc_dist\n",
        "                        pair_count+=1\n",
        "        if pair_count>0:\n",
        "            distances.append(pair_sum/pair_count)\n",
        "    if len(distances)==0:\n",
        "        return 0.0\n",
        "    import numpy as np\n",
        "    return float(np.mean(distances))\n",
        "\n",
        "def novelty_with_topN(user_topN, popularity_ranks):\n",
        "    ranks=[]\n",
        "    for u, top_items in user_topN.items():\n",
        "        for it in top_items:\n",
        "            ranks.append(popularity_ranks.get(it,9999999))\n",
        "    if len(ranks)==0:\n",
        "        return 0.0\n",
        "    import numpy as np\n",
        "    return float(np.mean(ranks))\n",
        "\n",
        "########################\n",
        "## 4) 최종 평가\n",
        "########################\n",
        "def evaluate_model_rbm_style_for_recgan(generator,\n",
        "                                        train_data, test_data,   # (u,i,r) list\n",
        "                                        all_users, all_items,\n",
        "                                        user_items_dict,\n",
        "                                        popularity_ranks,\n",
        "                                        movie_genres,\n",
        "                                        top_k_candidates=2000,\n",
        "                                        N=10,\n",
        "                                        rating_threshold=4.0):\n",
        "    \"\"\"\n",
        "    1) RMSE, MAE\n",
        "    2) 사용자별 TopN -> HR, cHR, AHAR\n",
        "    3) Coverage, Diversity(장르 Jaccard), Novelty(인기도 rank)\n",
        "    \"\"\"\n",
        "    # 1) RMSE, MAE\n",
        "    generator.eval()\n",
        "    preds, trues= [], []\n",
        "    for (u,i,r) in test_data:\n",
        "        user_tensor   = torch.LongTensor([u]).to(device)\n",
        "        item_tensor   = torch.LongTensor([[i]]).to(device)\n",
        "        rating_tensor = torch.FloatTensor([[0.0]]).to(device)\n",
        "        length_tensor = torch.LongTensor([1]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pr_2d= generator(user_tensor, item_tensor, rating_tensor, length_tensor)\n",
        "        preds.append(pr_2d.item())\n",
        "        trues.append(r)\n",
        "\n",
        "    RMSE_val= rmse(preds, trues)\n",
        "    MAE_val = mae(preds, trues)\n",
        "\n",
        "    # 2) TopN\n",
        "    user_topN= get_topN_for_all_users_recgan(\n",
        "        model=generator,\n",
        "        all_users=all_users,\n",
        "        all_items=all_items,\n",
        "        user_items_dict=user_items_dict,\n",
        "        popularity_ranks=popularity_ranks,\n",
        "        top_k_candidates=top_k_candidates,\n",
        "        N=N\n",
        "    )\n",
        "\n",
        "    # 3) HR, cHR, AHAR\n",
        "    hr_val, chr_val, ahar_val= evaluate_topN_metrics(user_topN, test_data,\n",
        "                                                     rating_threshold=rating_threshold, N=N)\n",
        "\n",
        "    # 4) Coverage, Diversity, Novelty\n",
        "    coverage_val= coverage_with_topN(user_topN, all_items)\n",
        "    diversity_val= diversity_with_topN(user_topN, movie_genres)\n",
        "    novelty_val= novelty_with_topN(user_topN, popularity_ranks)\n",
        "\n",
        "    return {\n",
        "        \"RMSE\": RMSE_val,\n",
        "        \"MAE\": MAE_val,\n",
        "        \"HR\": hr_val,\n",
        "        \"cHR\": chr_val,\n",
        "        \"AHAR\": ahar_val,\n",
        "        \"Coverage\": coverage_val,\n",
        "        \"Diversity\": diversity_val,\n",
        "        \"Novelty\": novelty_val\n",
        "    }"
      ],
      "metadata": {
        "id": "x5_iPy0pnYnw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7\n",
        "\n",
        "# (A) (u,i,r) 형태로 train_data, test_data 리스트 구성\n",
        "train_data_list= []\n",
        "for u, seq in user_seq_train.items():\n",
        "    for (i,r) in seq:\n",
        "        train_data_list.append((u,i,r))\n",
        "\n",
        "test_data_list= []\n",
        "for u, seq in user_seq_test.items():\n",
        "    for (i,r) in seq:\n",
        "        test_data_list.append((u,i,r))\n",
        "\n",
        "# 사용자별 이미 본 아이템\n",
        "user_items_dict= defaultdict(set)\n",
        "for (u,i,r) in train_data_list:\n",
        "    user_items_dict[u].add(i)\n",
        "\n",
        "# 장르, 인기도 rank (RBM 코드 비슷하게)\n",
        "def get_movie_genres():\n",
        "    \"\"\"\n",
        "    장르 비트필드. (예시)\n",
        "    실제로는 movies.csv를 parse하여 genre -> bitfield\n",
        "    여기서는 임시로 빈 dict or random\n",
        "    \"\"\"\n",
        "    return defaultdict(list)\n",
        "\n",
        "def get_popularity_ranks():\n",
        "    \"\"\"\n",
        "    아이템 인기도 rank(1=가장 인기)\n",
        "    \"\"\"\n",
        "    from collections import Counter\n",
        "    c= Counter()\n",
        "    for (u,i,r) in train_data_list:\n",
        "        c[i]+=1\n",
        "    sorted_items= sorted(c.items(), key=lambda x:x[1], reverse=True)\n",
        "    rank_dict= {}\n",
        "    rank=1\n",
        "    for (it,cnt) in sorted_items:\n",
        "        rank_dict[it]= rank\n",
        "        rank+=1\n",
        "    return rank_dict\n",
        "\n",
        "movie_genres= get_movie_genres()  # 실제로는 movies.csv에서 장르 파싱\n",
        "popularity_ranks= get_popularity_ranks()\n",
        "\n",
        "# DataLoader\n",
        "train_dataset= UserSequenceDataset(user_seq_train, max_seq_len=10)\n",
        "train_loader= DataLoader(train_dataset, batch_size=512, shuffle=True,\n",
        "                         collate_fn=collate_fn, drop_last=False)\n",
        "\n",
        "# RecGAN1\n",
        "gen1= RRecGAN_Generator(num_users, num_items, embed_dim=128, hidden_size=128, gru_type='basic')\n",
        "dis1= RRecGAN_Discriminator(num_users, num_items, embed_dim=128, hidden_size=128, gru_type='basic')\n",
        "\n",
        "print(\"\\n===== RecGAN1 (Basic GRU) 학습 =====\")\n",
        "gen1, dis1= train_rrecgan(\n",
        "    generator=gen1,\n",
        "    discriminator=dis1,\n",
        "    train_loader=train_loader,\n",
        "    num_epochs=10,      # 실제론 15~20+ / bigger hidden etc\n",
        "    g_lr=5e-4,\n",
        "    d_lr=5e-4,\n",
        "    lambda_mse=0.1,\n",
        "    grad_clip=5.0,\n",
        "    device=device,\n",
        "    S_g=1,\n",
        "    S_d=1\n",
        ")\n",
        "\n",
        "# 평가\n",
        "metrics1= evaluate_model_rbm_style_for_recgan(\n",
        "    generator=gen1,\n",
        "    train_data= train_data_list,\n",
        "    test_data=  test_data_list,\n",
        "    all_users= set(u for (u,i,r) in train_data_list+test_data_list),\n",
        "    all_items= set(i for (u,i,r) in train_data_list+test_data_list),\n",
        "    user_items_dict= user_items_dict,\n",
        "    popularity_ranks= popularity_ranks,\n",
        "    movie_genres= movie_genres,\n",
        "    top_k_candidates=2000,\n",
        "    N=10,\n",
        "    rating_threshold=4.0\n",
        ")\n",
        "print(\"\\n===== Evaluate RecGAN1 (RBM Style) =====\")\n",
        "for k,v in metrics1.items():\n",
        "    print(f\"{k} = {v:.4f}\")\n",
        "\n",
        "# RecGAN2\n",
        "gen2= RRecGAN_Generator(num_users, num_items, embed_dim=128, hidden_size=128, gru_type='modified')\n",
        "dis2= RRecGAN_Discriminator(num_users, num_items, embed_dim=128, hidden_size=128, gru_type='modified')\n",
        "\n",
        "print(\"\\n===== RecGAN2 (Modified GRU) 학습 =====\")\n",
        "gen2, dis2= train_rrecgan(\n",
        "    generator=gen2,\n",
        "    discriminator=dis2,\n",
        "    train_loader=train_loader,\n",
        "    num_epochs=10,\n",
        "    g_lr=5e-4,\n",
        "    d_lr=5e-4,\n",
        "    lambda_mse=0.1,\n",
        "    grad_clip=5.0,\n",
        "    device=device,\n",
        "    S_g=1,\n",
        "    S_d=1\n",
        ")\n",
        "\n",
        "metrics2= evaluate_model_rbm_style_for_recgan(\n",
        "    generator=gen2,\n",
        "    train_data= train_data_list,\n",
        "    test_data=  test_data_list,\n",
        "    all_users= set(u for (u,i,r) in train_data_list+test_data_list),\n",
        "    all_items= set(i for (u,i,r) in train_data_list+test_data_list),\n",
        "    user_items_dict= user_items_dict,\n",
        "    popularity_ranks= popularity_ranks,\n",
        "    movie_genres= movie_genres,\n",
        "    top_k_candidates=2000,\n",
        "    N=10,\n",
        "    rating_threshold=4.0\n",
        ")\n",
        "print(\"\\n===== Evaluate RecGAN2 (RBM Style) =====\")\n",
        "for k,v in metrics2.items():\n",
        "    print(f\"{k} = {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLvhfc1tnieL",
        "outputId": "d6da7c6a-9b1e-4364-deab-2eb85a64f769"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== RecGAN1 (Basic GRU) 학습 =====\n",
            "[Epoch 1/10] G_loss=1.0259, D_loss=1.4997\n",
            "[Epoch 2/10] G_loss=0.9163, D_loss=1.4280\n",
            "[Epoch 3/10] G_loss=0.7605, D_loss=1.3828\n",
            "[Epoch 4/10] G_loss=0.6835, D_loss=1.3808\n",
            "[Epoch 5/10] G_loss=0.7850, D_loss=1.4582\n",
            "[Epoch 6/10] G_loss=0.7143, D_loss=1.3740\n",
            "[Epoch 7/10] G_loss=0.7181, D_loss=1.3777\n",
            "[Epoch 8/10] G_loss=0.7079, D_loss=1.3962\n",
            "[Epoch 9/10] G_loss=0.7265, D_loss=1.3846\n",
            "[Epoch 10/10] G_loss=0.6939, D_loss=1.3870\n",
            "학습 완료!\n",
            "\n",
            "===== Evaluate RecGAN1 (RBM Style) =====\n",
            "RMSE = 3.6920\n",
            "MAE = 3.5341\n",
            "HR = 0.0087\n",
            "cHR = 0.5918\n",
            "AHAR = 10.9523\n",
            "Coverage = 0.0122\n",
            "Diversity = 0.0000\n",
            "Novelty = 910.9858\n",
            "\n",
            "===== RecGAN2 (Modified GRU) 학습 =====\n",
            "[Epoch 1/10] G_loss=1.4408, D_loss=1.2037\n",
            "[Epoch 2/10] G_loss=2.5654, D_loss=1.9370\n",
            "[Epoch 3/10] G_loss=1.0821, D_loss=1.4451\n",
            "[Epoch 4/10] G_loss=1827.6258, D_loss=1.4616\n",
            "[Epoch 5/10] G_loss=0.9232, D_loss=1.4313\n",
            "[Epoch 6/10] G_loss=0.6735, D_loss=1.4171\n",
            "[Epoch 7/10] G_loss=0.7513, D_loss=1.3983\n",
            "[Epoch 8/10] G_loss=0.7737, D_loss=1.4009\n",
            "[Epoch 9/10] G_loss=0.6815, D_loss=1.3907\n",
            "[Epoch 10/10] G_loss=0.7161, D_loss=1.3921\n",
            "학습 완료!\n",
            "\n",
            "===== Evaluate RecGAN2 (RBM Style) =====\n",
            "RMSE = 4.0522\n",
            "MAE = 3.9033\n",
            "HR = 0.0062\n",
            "cHR = 0.4218\n",
            "AHAR = 10.9656\n",
            "Coverage = 0.0464\n",
            "Diversity = 0.0000\n",
            "Novelty = 1015.1812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8\n",
        "\n",
        "def recommend_for_user(model, user_id, all_items, user_items_dict,\n",
        "                       popularity_ranks, N=10, top_k_candidates=2000):\n",
        "    \"\"\"\n",
        "    특정 user에 대해서만\n",
        "     - 이미 평가한 아이템 제외\n",
        "     - 인기도 rank 기반 후보 제한\n",
        "     - RecGAN 모델로 평점 예측 -> 상위 N\n",
        "    \"\"\"\n",
        "    rated_items= user_items_dict[user_id]\n",
        "    cands= [i for i in all_items if i not in rated_items]\n",
        "    if len(cands)> top_k_candidates:\n",
        "        cands= sorted(cands, key=lambda x: popularity_ranks.get(x,9999999))\n",
        "        cands= cands[:top_k_candidates]\n",
        "\n",
        "    scores=[]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for it_ in cands:\n",
        "            user_tensor   = torch.LongTensor([user_id]).to(device)\n",
        "            item_tensor   = torch.LongTensor([[it_]]).to(device)\n",
        "            rating_tensor = torch.FloatTensor([[0.0]]).to(device)\n",
        "            length_tensor = torch.LongTensor([1]).to(device)\n",
        "\n",
        "            pr_2d= model(user_tensor, item_tensor, rating_tensor, length_tensor)\n",
        "            scores.append((it_, pr_2d.item()))\n",
        "    scores.sort(key=lambda x:x[1], reverse=True)\n",
        "    top_items= [x[0] for x in scores[:N]]\n",
        "    return top_items\n",
        "\n",
        "\n",
        "def print_recommendations_for_user(model, user_id,\n",
        "                                   all_items, user_items_dict,\n",
        "                                   popularity_ranks,\n",
        "                                   ml_object,  # MovieLens 객체 (movieID->name 매핑)\n",
        "                                   N=10):\n",
        "    \"\"\"\n",
        "    user_id에게 추천된 아이템 N개를 영화 제목과 함께 출력\n",
        "    \"\"\"\n",
        "    top_items= recommend_for_user(model, user_id, all_items, user_items_dict,\n",
        "                                  popularity_ranks, N=N)\n",
        "    print(f\"\\n=== 추천 결과 for User {user_id} ===\")\n",
        "    for rank_idx, item_id in enumerate(top_items, start=1):\n",
        "        movie_name= ml_object.movieID_to_name.get(item_id, f\"Movie-{item_id}\")\n",
        "        print(f\"{rank_idx}. item_id={item_id}, title={movie_name}\")\n",
        "\n",
        "\n",
        "# 예시: RecGAN2 모델로, user 10에게 추천된 상위 10개 영화 출력\n",
        "some_user= 10\n",
        "print_recommendations_for_user(\n",
        "    model=gen2,        # RecGAN2 (Modified GRU)\n",
        "    user_id= some_user,\n",
        "    all_items= set(i for (u,i,r) in train_data_list+test_data_list),\n",
        "    user_items_dict= user_items_dict,\n",
        "    popularity_ranks= popularity_ranks,\n",
        "    ml_object= ml,     # MovieLens 객체( movieID_to_name 이용 )\n",
        "    N=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLAhsJCDvCG6",
        "outputId": "3eaaf8fa-0065-4fc9-d1e4-374e85633004"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 추천 결과 for User 10 ===\n",
            "1. item_id=2369, title=Movie-2369\n",
            "2. item_id=938, title=Movie-938\n",
            "3. item_id=3617, title=Movie-3617\n",
            "4. item_id=3308, title=Movie-3308\n",
            "5. item_id=2058, title=Movie-2058\n",
            "6. item_id=3996, title=Movie-3996\n",
            "7. item_id=1131, title=Movie-1131\n",
            "8. item_id=674, title=Movie-674\n",
            "9. item_id=1214, title=Movie-1214\n",
            "10. item_id=613, title=Movie-613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHMIfPPKvJ09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}